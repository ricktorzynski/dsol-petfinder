{"cells":[{"metadata":{"_uuid":"528d796fad1bbac916a9c402d2e34996d7355ddf"},"cell_type":"markdown","source":"### Notebook Name: DSOL Ensemble\n#### Description: This notebook features an overview of the competition, EDA (Exploratory Data Analysis) and Ensembling of different models.\n#### Version: 1\n#### Date Committed: 6 Jan 2018\n#### Date Submitted: 6 Jan 2018\n#### Score: \n#### Place: 157/345\n\n#### Contributors:\n#### Christopher Himmel\n#### Rick Torzynski\n#### Shreesha Pillangere Ramachandra\n#### Muthu\n#### Neha Varshney\n#### Sandeep\n#### Viswanathan Kodumudi Sivakumar\n#### Mahesh\n"},{"metadata":{"_uuid":"8e3394d063fa0a443282af46ab8ae561b65e83af"},"cell_type":"markdown","source":"![](https://blog.groomit.me/wp-content/uploads/2018/02/petfinder2.jpg)"},{"metadata":{"_uuid":"405f83116c840adf7fb95ee0da48ce184cf8ad8c"},"cell_type":"markdown","source":"## PetFinder.my Adoption Prediction"},{"metadata":{"_uuid":"a047a79f124157561a53bd7c39105bbfd0360e3a"},"cell_type":"markdown","source":"## Table of contents"},{"metadata":{"_uuid":"b0d13d2706246ced752063429bce9dfe32299c1b"},"cell_type":"markdown","source":"- [Data Columns](#1)\n- [Dependencies](#2)\n- [Preparation](#3)\n- [Data Description](#4)\n- [Visualization](#5)\n- [Metric](#6)\n- [Data Cleaning](#10)\n- [Tree Ensembling](#7)\n- [Predictions](#8)\n- [Kaggle Submission](#9)"},{"metadata":{"_uuid":"31c6699700def1d9dac84e72ab2be45352dbfa40"},"cell_type":"markdown","source":"## Data columns <a id=\"1\"></a>\n\n[Source](https://www.kaggle.com/c/petfinder-adoption-prediction/data)\n\n* PetID - Unique hash ID of pet profile\n* AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n* Type - Type of animal (1 = Dog, 2 = Cat)\n* Name - Name of pet (Empty if not named)\n* Age - Age of pet when listed, in months\n* Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n* Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n* Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n* Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n* Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n* Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n* MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n* FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n* Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n* Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n* Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n* Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n* Quantity - Number of pets represented in profile\n* Fee - Adoption fee (0 = Free)\n* State - State location in Malaysia (Refer to StateLabels dictionary)\n* RescuerID - Unique hash ID of rescuer\n* VideoAmt - Total uploaded videos for this pet\n* PhotoAmt - Total uploaded photos for this pet\n* Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n"},{"metadata":{"_uuid":"85c18e3eeac2d5ecfd2c73525669f4f78275f372"},"cell_type":"markdown","source":"## Dependencies <a id=\"2\"></a>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# For notebook plotting\n%matplotlib inline\n\n# Standard libraries\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pprint import pprint\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nimport lightgbm as lgb\nimport xgboost as xgb\n\n\n\n# Seed for reproducability\nseed = 12345\nnp.random.seed(seed)\n\n# Info about dataset\nprint('Files and directories: \\n{}\\n'.format(os.listdir(\"../input\")))\nprint('Within the train directory: \\n{}\\n'.format(os.listdir(\"../input/train\")))\nprint('Within the test directory: \\n{}\\n'.format(os.listdir(\"../input/test\")))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd56bd8a134acf5c801a6936e84fdb0e34e314b1"},"cell_type":"markdown","source":"## Preparation <a id=\"3\"></a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read in data\nKAGGLE_DIR = '../input/'\n\ntrain_df = pd.read_csv(KAGGLE_DIR + \"train/train.csv\")\ntest_df = pd.read_csv(KAGGLE_DIR + \"test/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb8e53c5b4e3ef65f7fe8c74014ff4d2ef2df4f6"},"cell_type":"markdown","source":"## Data Description <a id=\"4\"></a>"},{"metadata":{"_kg_hide-input":true,"_uuid":"a15e2f9884d49c6ef0c68712d3b1acf72ec7947d","trusted":true},"cell_type":"code","source":"# Stats\nprint('Data Statistics:')\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"f8f75ffe959ccb1ff0318fc3cbb9a0651ab0873a","trusted":true},"cell_type":"code","source":"# Types\nprint('Types: ')\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"ef5d56c772b4442e32b2637e94141cb09ac70751","trusted":true},"cell_type":"code","source":"# Overview\nprint('This dataset has {} rows and {} columns'.format(train_df.shape[0], train_df.shape[1]))\nprint('Example rows:')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"849a8882b5644afd93a0c3e36d0f26938a2823be"},"cell_type":"markdown","source":"## Visualization <a id=\"5\"></a>"},{"metadata":{"_kg_hide-input":true,"_uuid":"29bd62fd6c6b2842f0f60b02d75030828dae7155","trusted":true},"cell_type":"code","source":"# Type distribution\ntrain_df['Type'].value_counts().rename({1:'Dog',\n                                        2:'Cat'}).plot(kind='barh',\n                                                       figsize=(15,6))\nplt.yticks(fontsize='xx-large')\nplt.title('Type Distribution', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"48278ee8b49dbd0c91073b7b3abf527047c8f1ce","trusted":true},"cell_type":"code","source":"# Gender distribution\ntrain_df['Gender'].value_counts().rename({1:'Male',\n                                          2:'Female',\n                                          3:'Mixed (Group of pets)'}).plot(kind='barh', \n                                                                           figsize=(15,6))\nplt.yticks(fontsize='xx-large')\nplt.title('Gender distribution', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"fab72b33d1b53779b67293798fde56430e454069","trusted":true},"cell_type":"code","source":"# Age distribution \ntrain_df['Age'][train_df['Age'] < 50].plot(kind='hist', \n                                           bins = 100, \n                                           figsize=(15,6), \n                                           title='Age distribution')\nplt.title('Age distribution', fontsize='xx-large')\nplt.xlabel('Age in months')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"ec8f191cbf0372bc687316828e87bdf6d841381d","trusted":true},"cell_type":"code","source":"# Photo amount distribution\ntrain_df['PhotoAmt'].plot(kind='hist', \n                          bins=30, \n                          xticks=list(range(31)), \n                          figsize=(15,6))\nplt.title('PhotoAmt distribution', fontsize='xx-large')\nplt.xlabel('Photos')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"34d8aed4cdc93ce6af0c29c27c392c62c22aa49f","trusted":true},"cell_type":"code","source":"# Target variable (Adoption Speed)\nprint('The values are determined in the following way:\\n\\\n0 - Pet was adopted on the same day as it was listed.\\n\\\n1 - Pet was adopted between 1 and 7 days (1st week) after being listed.\\n\\\n2 - Pet was adopted between 8 and 30 days (1st month) after being listed.\\n\\\n3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\\n\\\n4 - No adoption after 100 days of being listed.\\n\\\n(There are no pets in this dataset that waited between 90 and 100 days).')\n\n# Plot\ntrain_df['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh', \n                                                                          figsize=(15,6))\nplt.title('Adoption Speed (Target Variable)', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"cad6831020c455593ee66335ff6aa3a8a283c3fe","trusted":true},"cell_type":"code","source":"# Example Description (of Nibble) ^^ \nprint('Example Description (of Nibble) ^^ : ')\ntrain_df['Description'][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b833d070cafe9f021cb880daba586efe519f4c8"},"cell_type":"markdown","source":"## Metric <a id=\"6\"></a>"},{"metadata":{"_uuid":"41ac4921f6f3e18591893d69c75e51f966054e94"},"cell_type":"markdown","source":"The metric used for this competition is called ''Quadratic Weighted Kappa''.\n\nWe can use [scikit-learn's 'cohen_kappa_score' function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html) almost straight out-of-the-box for measuring our predictions."},{"metadata":{"_uuid":"a96705a834ae02654879a39142474e8a9e01d810","trusted":true},"cell_type":"code","source":"# Metric used for this competition (Quadratic Weigthed Kappa aka Quadratic Cohen Kappa Score)\ndef metric(y1,y2):\n    return cohen_kappa_score(y1,y2, weights='quadratic')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b91cd48698dedb4254c9c5d1280164bfded0f9a3"},"cell_type":"markdown","source":"## Loading Sentiment Data From json files <a id=\"10\"></a>"},{"metadata":{"_uuid":"0f093d9e8e92279fa3f4a986328a4f2aa0e95a05","trusted":true},"cell_type":"code","source":"import json\nfrom pprint import pprint\n\ndef loadSentimentData(df):\n    sentiments_mag = []\n    sentiments_score = []\n    path = '../input/train_sentiment/'\n    for petId in df['PetID']:\n        try:\n            with open(path + str(petId) + '.json') as f:\n                data = json.load(f)\n                sentiments_mag.append(data['documentSentiment']['magnitude'])\n                sentiments_score.append(data['documentSentiment']['score'])\n        except:\n            sentiments_mag.append(0)\n            sentiments_score.append(0)\n\n    df['Sentiment_mag'] = np.array(sentiments_mag) \n    df['Sentiment_score'] = np.array(sentiments_score) \n    return df\n    \ntrain_df = loadSentimentData(train_df)\ntest_df = loadSentimentData(test_df)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1b8808a4ad448c31a85e45b247e14b425f07246"},"cell_type":"markdown","source":"## Data Cleaning <a id=\"10\"></a>"},{"metadata":{"_uuid":"d47447eafad4c662ab2056940b1ab467dfc9947f","trusted":true},"cell_type":"code","source":"# Clean up DataFrames\ntarget = train_df['AdoptionSpeed']\nclean_x_train = train_df.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed'])\nclean_x_test = test_df.drop(columns=['Name', 'RescuerID', 'Description', 'PetID'])\ntarget.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56599b097782427490135ed08d62027fdbbdb4fa"},"cell_type":"markdown","source":"## Correlation Matrix <a id=\"3\"></a>"},{"metadata":{"_uuid":"a109c951b823ed755b6f8b8689d6f4fe8e5a5a05","trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr_df = train_df.drop(columns=['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed'])\ncorr_df['AdoptionSpeed'] = target\ncorr = corr_df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"845c9c2fba78a63a52bb742ea9a785248cdddd50"},"cell_type":"markdown","source":"## Feature Importance <a id=\"3\"></a>"},{"metadata":{"_uuid":"4325680518644e0fea7910593c44f7fe4bc3186b","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n%matplotlib inline\n\nmodel = RandomForestClassifier()\nmodel.fit(clean_x_train, target)\n\n(pd.Series(model.feature_importances_, index=clean_x_train.columns)\n   .nlargest(30)\n   .plot(kind='barh'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bee07c109157ed21434cda4282cd0ef96e28435d","trusted":true},"cell_type":"code","source":"#check types of features\nclean_x_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7070443821267aa79388544eaac5c8351b001031"},"cell_type":"markdown","source":"## Normalization <a id=\"3\"></a>"},{"metadata":{"_uuid":"4a5ed6616d496a349390db77c28c6794be757ab5","trusted":true},"cell_type":"code","source":"#Data Normalization if needed\nfrom sklearn import preprocessing\ndef normalizeData(df):\n    x = df.values #returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df = pd.DataFrame(x_scaled)\n    return df\n#Normalize if needed\n# clean_x_train = normalizeData(clean_x_train)\n# clean_x_test = normalizeData(clean_x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad39f1988c9423da744838241262e7841d1272b2","trusted":true},"cell_type":"code","source":"print(clean_x_train.shape)\nprint(target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63b34389896df57fa42e1f5a72ce5714a7650f0d"},"cell_type":"markdown","source":"## Data Split <a id=\"3\"></a>"},{"metadata":{"_uuid":"9f304ff77c3a2c4102043375f1c8320e3804bd9f","trusted":true},"cell_type":"code","source":"# Splitting Data into Training and Validation set(75:25)\nfrom sklearn.model_selection import train_test_split\nx_train, x_validation, y_train, y_validation = train_test_split(clean_x_train, target, test_size=0.25, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba60a40bc08f58037a6c8137e9eb8b4d5f7666c4"},"cell_type":"markdown","source":"## Tree Ensembling <a id=\"7\"></a>"},{"metadata":{"_uuid":"5fb295cee9c2c28286beb33d72aded328953b566"},"cell_type":"markdown","source":"We will use predictions from both a [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), an [Extra Trees Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html), an [AdaBoost Classifier.](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) and a [Gaussian Naive Bayes Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html). Later we will take the average of all models to get the final predictions. [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) is used to get near-optimal parameters for almost all models."},{"metadata":{"trusted":true,"_uuid":"0680fd400179086457a76f1a676b62cc00901ab4"},"cell_type":"code","source":"params = {'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'num_class':5,\n    'metric': 'multi_logloss',\n    'max_bin': 100,\n    'max_depth': 20,\n    'num_leaves': 80,\n    'feature_fraction': 0.4,\n    'bagging_fraction': 0.6,\n    'bagging_freq': 17,\n    'num_leaves': 80,\n    'max_depth': 9,\n    'learning_rate': 0.01,\n    'bagging_fraction': 0.85,\n    'feature_fraction': 0.8,\n    'min_split_gain': 0.01,\n    'min_child_samples': 150,\n    'min_child_weight': 0.1,     \n}\n\nd_train = lgb.Dataset(x_train, label=y_train)\nclean_d_train = lgb.Dataset(clean_x_train, label=target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2d2d6e528d79f1aa1294200671b88ca28a2335d"},"cell_type":"markdown","source":"### Create base models"},{"metadata":{"trusted":true,"_uuid":"fc6334de5d77d0355e38e8307fb893d9264972da"},"cell_type":"code","source":"random_forest = RandomForestClassifier()\nextra_trees = ExtraTreesClassifier()\nada_boost = AdaBoostClassifier()\nxg_boost = xgb.XGBClassifier()\n\nlgb_cv = lgb.cv(params, d_train, num_boost_round=10000,\n                 nfold=3, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=100)\nnround = lgb_cv['multi_logloss-mean'].index(np.min(lgb_cv['multi_logloss-mean']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa177394872b68fea0577fb692c19c37f6ededa2","trusted":true},"cell_type":"code","source":"grid_search = False\nif grid_search == True:\n\n    # Create parameters to use for Grid Search\n    rand_forest_grid = {\n        'bootstrap': [True],\n        'max_depth': [77, 80, 83, 85],\n        'max_features': ['auto'],\n        'min_samples_leaf': [5, 10],\n        'min_samples_split': [5, 10],\n        'n_estimators': [175, 200, 225]\n    }\n\n    extra_trees_grid = {\n        'bootstrap' : [False, True], \n        'criterion' : ['gini', 'entropy'], \n        'max_depth' : [77, 80, 83, 85], \n        'max_features': ['auto'], \n        'min_samples_leaf': [5, 10], \n        'min_samples_split': [5, 10],\n        'n_estimators': [175, 200, 225]\n    }\n\n    adaboost_grid = {\n        'n_estimators' : [200, 225, 250],\n        'learning_rate' : [.1, .2, .3, .4, .5],\n        'algorithm' : ['SAMME.R']\n    }\n\n    xgboost_grid = {\"max_depth\": [1,2,3],\n                  \"max_features\" : [1.0, 1.5],\n                  \"min_samples_leaf\" : [3,5,9],\n                  \"n_estimators\": [300, 500],\n                  \"learning_rate\": [0.02,0.05,0.1]}\n\n    # Search parameter space\n    rand_forest_gridsearch = GridSearchCV(estimator = random_forest, \n                               param_grid = rand_forest_grid, \n                               cv = 3, \n                               n_jobs = -1, \n                               verbose = 1)\n\n    extra_trees_gridsearch = GridSearchCV(estimator = extra_trees, \n                               param_grid = extra_trees_grid, \n                               cv = 3, \n                               n_jobs = -1, \n                               verbose = 1)\n\n    adaboost_gridsearch = GridSearchCV(estimator = ada_boost, \n                               param_grid = adaboost_grid, \n                               cv = 3, \n                               n_jobs = -1, \n                               verbose = 1)\n    xgboost_gridsearch = GridSearchCV(estimator = xg_boost, \n                              param_grid=xgboost_grid, \n                              cv = 3, \n                              n_jobs = -1, \n                              verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce56744dfb55a1b2cb8e66c1d65a654466100327","scrolled":true,"trusted":true},"cell_type":"code","source":"# Fit the grid_search models\nsubmission=True\nif submission==False and grid_search==True:\n    rand_forest_gridsearch.fit(x_train, y_train)\n    extra_trees_gridsearch.fit(x_train, y_train)\n    adaboost_gridsearch.fit(x_train, y_train)\n    xgboost_gridsearch.fit(x_train, y_train)\n    lightGBM = lgb.train(params, d_train, nround)\n    \n    # What are the best parameters for each model\n    print('Random Forest model:\\n{}\\n'.format(rand_forest_gridsearch.best_params_))\n    print('Extra Trees model:\\n{}\\n'.format(extra_trees_gridsearch.best_params_))\n    print('Adaboost model:\\n{}\\n'.format(adaboost_gridsearch.best_params_))\n    print('XGboost model:\\n{}\\n'.format(xgboost_gridsearch.best_params_))\n\n    # Get Validation predictions\n    predictions_rf = rand_forest_gridsearch.predict(x_validation)\n    predictions_et = extra_trees_gridsearch.predict(x_validation)\n    predictions_ab = adaboost_gridsearch.predict(x_validation)\n    predictions_xgb = xgboost_gridsearch.predict(x_validation)\n\n    y_pred_lgbm = lightGBM.predict(x_validation)\n    prediction_lgbm = []\n    for pred in y_pred_lgbm:\n        prediction_lgbm.append(pred.argmax())\n\n    # Measure of performance \n    # Useful for checking overfitting, performance, etc.\n    print('Random Forest score: ', metric(predictions_rf, y_validation))\n    print('Extra Trees score: ', metric(predictions_et, y_validation))\n    print('Adaboost score: ', metric(predictions_ab, y_validation))\n    print('XGBoost score: ', metric(predictions_xgb, y_validation))\n    print('LightGBM score: ', metric(predictions_lgbm, y_validation))\n\n    # Combine predictions\n    validation_predictions = []\n    # Get average of predictions\n    for pred in zip(predictions_rf, predictions_et, predictions_ab, predictions_xgb, predictions_lgbm):\n       validation_predictions.append(int(round((sum(pred)) / 5, 0)))\n\n    print('Combined Model Validation Kappa Score: ', metric(validation_predictions, y_validation))\n    print('Combined Model Validation accuracy Score: ', accuracy_score(validation_predictions, y_validation))\n\n#Random Forest score:  0.3548276726741826\n#Extra Trees score:  0.3103631633681623\n#Adaboost score:  0.3258035539320042\n#XGBoost score:  0.35960892487423246\n#LightGBM score:  0.3675133483960088\n\n#Combined Model Validation Kappa Score:  0.3674064960957891\n#Combined Model Validation accuracy Score:  0.4022405974926647\n \nelse:\n    lightGBM = lgb.train(params, d_train, nround)\n    y_pred_lgbm = lightGBM.predict(x_validation)\n    predictions_lgbm = []\n    for pred in y_pred_lgbm:\n        predictions_lgbm.append(pred.argmax())\n    print('LightGBM score: ', metric(predictions_lgbm, y_validation))\n    \nprint('done')\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"040507e26d9c016eabed8c3a2de69ac80ab96c0c"},"cell_type":"markdown","source":"## Predictions <a id=\"8\"></a>\n### Create parameters to use for Grid Search"},{"metadata":{"_uuid":"c672da45b2cfb2f99472505ab7591c6d9dac8168","trusted":true},"cell_type":"code","source":"rand_forest_grid = {\n    'bootstrap': [True],\n    'max_depth': [77],\n    'max_features': ['auto'],\n    'min_samples_leaf': [5],\n    'min_samples_split': [10],\n    'n_estimators': [200]\n}\n\nextra_trees_grid = {\n    'bootstrap' : [False], \n    'criterion' : ['entropy'], \n    'max_depth' : [83], \n    'max_features': ['auto'], \n    'min_samples_leaf': [5], \n    'min_samples_split': [5],\n    'n_estimators': [225]\n}\n\nadaboost_grid = {\n    'n_estimators' : [200],\n    'learning_rate' : [.3],\n    'algorithm' : ['SAMME.R']\n}\n\nxgboost_grid = {\"max_depth\": [3],\n              \"max_features\" : [1.0],\n              \"min_samples_leaf\" : [3],\n              \"n_estimators\": [300],\n              \"learning_rate\": [0.1]}\n\nrand_forest_gridsearch = GridSearchCV(estimator = random_forest, \n                           param_grid = rand_forest_grid, \n                           cv = 3, \n                           n_jobs = -1, \n                           verbose = 1)\n\nextra_trees_gridsearch = GridSearchCV(estimator = extra_trees, \n                           param_grid = extra_trees_grid, \n                           cv = 3, \n                           n_jobs = -1, \n                           verbose = 1)\n\nadaboost_gridsearch = GridSearchCV(estimator = ada_boost, \n                           param_grid = adaboost_grid, \n                           cv = 3, \n                           n_jobs = -1, \n                           verbose = 1)\nxgboost_gridsearch = GridSearchCV(estimator = xg_boost, \n                          param_grid=xgboost_grid, \n                          cv = 3, \n                          n_jobs = -1, \n                          verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f717195c45786b0d2c988856c9241db292a9352e","trusted":true},"cell_type":"code","source":"# Final Model\n# Fit the models\nrand_forest_gridsearch.fit(clean_x_train, target)\nextra_trees_gridsearch.fit(clean_x_train, target)\nadaboost_gridsearch.fit(clean_x_train, target)\nxgboost_gridsearch.fit(clean_x_train, target)\nlightgbm = lgb.train(params, clean_d_train, nround)\n\n# Get Final predictions\npredictions_rf = rand_forest_gridsearch.predict(clean_x_test)\npredictions_et = extra_trees_gridsearch.predict(clean_x_test)\npredictions_ab = adaboost_gridsearch.predict(clean_x_test)\npredictions_xgb = xgboost_gridsearch.predict(clean_x_test)\n\ny_pred_lgbm = lightGBM.predict(clean_x_test)\npredictions_lgbm = []\nfor pred in y_pred_lgbm:\n    predictions_lgbm.append(pred.argmax())\n\n# Combine predictions\nfinal_predictions = []\n# Get average of predictions\nfor pred in zip(predictions_rf, predictions_et, predictions_ab, predictions_xgb, predictions_lgbm):\n   final_predictions.append(int(round((sum(pred)) / 5, 0)))\n\nprint('done')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a065da159fff1a7ce41651a3bfa8e2d014fb8c32","trusted":true},"cell_type":"code","source":"# Compare predictions\nprediction_df = pd.DataFrame({'PetID' : test_df['PetID'],\n                             'Random Forest' : predictions_rf,\n                             'Extra Trees' : predictions_et,\n                             'Adaboost' : predictions_ab,\n                             'XGBoost' : predictions_xgb,\n                             'lightGBM' : predictions_lgbm\n})\n\nprediction_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a0b5ea811583946b65ac95b15da51c73519e2d1"},"cell_type":"markdown","source":"## Kaggle Submission <a id=\"9\"></a>"},{"metadata":{"_uuid":"f508f56d4cab23c936752a1033028117e5a4b08c","trusted":true},"cell_type":"code","source":"# Store predictions for Kaggle Submission\nsubmission_df = pd.DataFrame(data={'PetID' : test_df['PetID'], \n                                   'AdoptionSpeed' : final_predictions})\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4913790918edf834a2d832e320b762be4c221527","trusted":true},"cell_type":"code","source":"# Check submission\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4047f516ef37e45ff3edb7b06932a643fef2547a","trusted":true},"cell_type":"code","source":"# Compare distributions of training set and test set (Adoption Speed)\n\n# Plot 1\nplt.figure(figsize=(15,4))\nplt.subplot(211)\ntrain_df['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh')\nplt.title('Target Variable distribution in training set', fontsize='large')\n\n# Plot 2\nplt.subplot(212)\nsubmission_df['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh')\nplt.title('Target Variable distribution in predictions')\n\nplt.subplots_adjust(top=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ed86254f0c7c987d20428a9c18ec05b29ef221","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b98bd1561ccf71bff7714dbf2938f46ba436a8f","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}